{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4abd1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n",
      "Downloading Model from https://www.modelscope.cn to directory: /Users/zengqiang/.cache/modelscope/hub/models/iic/SenseVoiceSmall\n",
      "Downloading Model from https://www.modelscope.cn to directory: /Users/zengqiang/.cache/modelscope/hub/models/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunasr\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpostprocess_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rich_transcription_postprocess\n\u001b[32m      5\u001b[39m model = AutoModel(\n\u001b[32m      6\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33miic/SenseVoiceSmall\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     vad_model=\u001b[33m\"\u001b[39m\u001b[33mfsmn-vad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     vad_kwargs={\u001b[33m\"\u001b[39m\u001b[33mmax_single_segment_time\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m30000\u001b[39m},\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m res = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./examples/vad_example.wav\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m text = rich_transcription_postprocess(res[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/funasr/auto/auto_model.py:306\u001b[39m, in \u001b[36mAutoModel.generate\u001b[39m\u001b[34m(self, input, input_len, **cfg)\u001b[39m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inference(\u001b[38;5;28minput\u001b[39m, input_len=input_len, **cfg)\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference_with_vad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/funasr/auto/auto_model.py:383\u001b[39m, in \u001b[36mAutoModel.inference_with_vad\u001b[39m\u001b[34m(self, input, input_len, **cfg)\u001b[39m\n\u001b[32m    381\u001b[39m deep_update(\u001b[38;5;28mself\u001b[39m.vad_kwargs, cfg)\n\u001b[32m    382\u001b[39m beg_vad = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvad_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvad_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcfg\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m end_vad = time.time()\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m#  FIX(gcf): concat the vad clips for sense vocie model for better aed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/funasr/auto/auto_model.py:345\u001b[39m, in \u001b[36mAutoModel.inference\u001b[39m\u001b[34m(self, input, input_len, model, kwargs, key, **cfg)\u001b[39m\n\u001b[32m    343\u001b[39m time1 = time.perf_counter()\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     res = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    347\u001b[39m         results = res[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [{\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m}]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/funasr/models/fsmn_vad_streaming/model.py:700\u001b[39m, in \u001b[36mFsmnVADStreaming.inference\u001b[39m\u001b[34m(self, data_in, data_lengths, key, tokenizer, frontend, cache, **kwargs)\u001b[39m\n\u001b[32m    697\u001b[39m audio_sample_i = audio_sample[i * chunk_stride_samples : (i + \u001b[32m1\u001b[39m) * chunk_stride_samples]\n\u001b[32m    699\u001b[39m \u001b[38;5;66;03m# extract fbank feats\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m speech, speech_lengths = \u001b[43mextract_fbank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43maudio_sample_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msound\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrontend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrontend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrontend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_final\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mis_final\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m time3 = time.perf_counter()\n\u001b[32m    708\u001b[39m meta_data[\u001b[33m\"\u001b[39m\u001b[33mextract_feat\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime3\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mtime2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/funasr/utils/load_utils.py:216\u001b[39m, in \u001b[36mextract_fbank\u001b[39m\u001b[34m(data, data_len, data_type, frontend, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m         data_len.append(data_i.shape[\u001b[32m0\u001b[39m])\n\u001b[32m    214\u001b[39m     data = pad_sequence(data_list, batch_first=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# data: [batch, N]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m data, data_len = \u001b[43mfrontend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_len, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    219\u001b[39m     data_len = torch.tensor([data_len])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/funasr/frontends/wav_frontend.py:445\u001b[39m, in \u001b[36mWavFrontendOnline.forward\u001b[39m\u001b[34m(self, input, input_lengths, **kwargs)\u001b[39m\n\u001b[32m    437\u001b[39m frame_from_waveforms = \u001b[38;5;28mint\u001b[39m(\n\u001b[32m    438\u001b[39m     (cache[\u001b[33m\"\u001b[39m\u001b[33mwaveforms\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m1\u001b[39m] - \u001b[38;5;28mself\u001b[39m.frame_sample_length)\n\u001b[32m    439\u001b[39m     / \u001b[38;5;28mself\u001b[39m.frame_shift_sample_length\n\u001b[32m    440\u001b[39m     + \u001b[32m1\u001b[39m\n\u001b[32m    441\u001b[39m )\n\u001b[32m    442\u001b[39m minus_frame = (\n\u001b[32m    443\u001b[39m     (\u001b[38;5;28mself\u001b[39m.lfr_m - \u001b[32m1\u001b[39m) // \u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache[\u001b[33m\"\u001b[39m\u001b[33mreserve_waveforms\u001b[39m\u001b[33m\"\u001b[39m].numel() == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    444\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m feats, feats_lengths, lfr_splice_frame_idxs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_lfr_cmvn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeats_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lfr_m == \u001b[32m1\u001b[39m:\n\u001b[32m    449\u001b[39m     cache[\u001b[33m\"\u001b[39m\u001b[33mreserve_waveforms\u001b[39m\u001b[33m\"\u001b[39m] = torch.empty(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/funasr/frontends/wav_frontend.py:397\u001b[39m, in \u001b[36mWavFrontendOnline.forward_lfr_cmvn\u001b[39m\u001b[34m(self, input, input_lengths, is_final, cache, **kwargs)\u001b[39m\n\u001b[32m    393\u001b[39m     mat, cache[\u001b[33m\"\u001b[39m\u001b[33mlfr_splice_cache\u001b[39m\u001b[33m\"\u001b[39m][i], lfr_splice_frame_idx = \u001b[38;5;28mself\u001b[39m.apply_lfr(\n\u001b[32m    394\u001b[39m         mat, \u001b[38;5;28mself\u001b[39m.lfr_m, \u001b[38;5;28mself\u001b[39m.lfr_n, is_final\n\u001b[32m    395\u001b[39m     )\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cmvn_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m     mat = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_cmvn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcmvn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    398\u001b[39m feat_length = mat.size(\u001b[32m0\u001b[39m)\n\u001b[32m    399\u001b[39m feats.append(mat)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/funasr/frontends/wav_frontend.py:269\u001b[39m, in \u001b[36mWavFrontendOnline.apply_cmvn\u001b[39m\u001b[34m(inputs, cmvn)\u001b[39m\n\u001b[32m    266\u001b[39m dtype = inputs.dtype\n\u001b[32m    267\u001b[39m frame, dim = inputs.shape\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m means = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmvn\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28mvars\u001b[39m = np.tile(cmvn[\u001b[32m1\u001b[39m:\u001b[32m2\u001b[39m, :dim], (frame, \u001b[32m1\u001b[39m))\n\u001b[32m    271\u001b[39m inputs += torch.from_numpy(means).type(dtype).to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/numpy/lib/_shape_base_impl.py:1284\u001b[39m, in \u001b[36mtile\u001b[39m\u001b[34m(A, reps)\u001b[39m\n\u001b[32m   1280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx.array(A, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, subok=\u001b[38;5;28;01mTrue\u001b[39;00m, ndmin=d)\n\u001b[32m   1281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m# Note that no copy of zero-sized arrays is made. However since they\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m# have no data there is no risk of an inadvertent overwrite.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m     c = \u001b[43m_nx\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (d < c.ndim):\n\u001b[32m   1286\u001b[39m     tup = (\u001b[32m1\u001b[39m,)*(c.ndim-d) + tup\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codespace/osml-playground/.venv/lib/python3.12/site-packages/torch/_tensor.py:1062\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1060\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype=dtype)\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy().astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from funasr import AutoModel\n",
    "from funasr.utils.postprocess_utils import rich_transcription_postprocess\n",
    "\n",
    "\n",
    "model = AutoModel(\n",
    "    model=\"iic/SenseVoiceSmall\",\n",
    "    vad_model=\"fsmn-vad\",\n",
    "    vad_kwargs={\"max_single_segment_time\": 30000},\n",
    ")\n",
    "\n",
    "res = model.generate(\n",
    "  input=\"./examples/vad_example.wav\"\n",
    ")\n",
    "\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osml-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
